# é…ç½®è¯´æ˜ï¼š
# 1. ç¯å¢ƒå˜é‡ QQ_TOKEN: é…ç½®tokenè´¦å·ä¿¡æ¯æ”¯æŒå¤šè´¦å·åˆ†éš”ç¬¦ï¼š#
# 2. ç¯å¢ƒå˜é‡ qqyd_ua: é…ç½®UAä¿¡æ¯
# 3. å¯é…ç½®è¿‡æ£€æµ‹æ¥å£
# 4. ç¯å¢ƒå˜é‡ qqyd_proxy: é…ç½®ä»£ç†è¿æ¥ï¼Œæ³¨æ„ä»£ç†æ—¶é•¿é€‰æ‹©ï¼æ³¨æ„ä»£ç†æ—¶é•¿é€‰æ‹©ï¼æ³¨æ„ä»£ç†æ—¶é•¿é€‰æ‹©ï¼åŒä¸€è´¦å·è¿è¡Œæ—¶ä¸è¦æ¢ipï¼ˆ4.0æ›´æ–°å†…å®¹ï¼‰
# æ´»åŠ¨å…¥å£ https://img.hnking.cn/blog/202509041844746.png


import time, json, random, requests, os
from urllib.parse import urlparse, parse_qs, unquote


PROXY_URL = os.getenv("qqyd_proxy")
UA_USER_AGENT = os.getenv("qqyd_ua")
# é…ç½®
API_URL = ''  # æ£€æµ‹æ–‡ç« æäº¤æ¥å£URL


def get_random_r():
    return str(random.uniform(0, 1))


def gettime():
    return str(int(time.time() * 1000))


def extract_biz(url):
    """ä»å¾®ä¿¡å…¬ä¼—å·æ–‡ç« é“¾æ¥ä¸­æå–__bizå‚æ•°å€¼"""
    # è§£æURL
    parsed_url = urlparse(url)

    # è§£ææŸ¥è¯¢å‚æ•°
    query_params = parse_qs(parsed_url.query)

    # æå–__bizå‚æ•°
    if '__biz' in query_params:
        return query_params['__biz'][0]
    else:
        return None


def getHomeInfo():
    """è·å–é¦–é¡µä¿¡æ¯"""
    url = 'https://read.tslu.cn/abaaba/getHomeInfo/'
    params = {'token': TOKEN}
    headers = {
        'Host': 'read.tslu.cn',
        'Connection': 'keep-alive',
        'Accept': 'application/json, text/javascript, */*; q=0.01',
        'User-Agent': UA_USER_AGENT,
        'Origin': 'http://we.e9l.cn',
        'Sec-Fetch-Site': 'cross-site',
        'Sec-Fetch-Mode': 'cors',
        'Sec-Fetch-Dest': 'empty',
        'Referer': 'http://we.e9l.cn/',
        'Accept-Encoding': 'gzip, deflate, br',
        'Accept-Language': 'zh-CN,zh;q=0.9',
    }
    try:
        response = requests.get(url, headers=headers, params=params, proxies=proxies).json()
        if response.get('code') == 0:
            home_data = response.get('data', {})
            print(
                f"é¦–é¡µä¿¡æ¯ - ç”¨æˆ·ID: {home_data.get('id', 'æœªçŸ¥')} | ç´¯è®¡é˜…è¯»: {home_data.get('dayreads', 0)}å¤© | é‡‘å¸: {home_data.get('gold', 0)}")
            return home_data
        else:
            print(f"é¦–é¡µä¿¡æ¯è·å–å¤±è´¥: {response.get('msg', 'æœªçŸ¥é”™è¯¯')}")
    except Exception as e:
        print(f"é¦–é¡µä¿¡æ¯è¯·æ±‚å¼‚å¸¸: {str(e)}")
    return None


def extract_parameters(url):
    """ä»URLä¸­æå–tã€chã€uå‚æ•°"""
    # è§£æURL
    parsed_url = urlparse(url)

    # æå–æŸ¥è¯¢å‚æ•°
    query_params = parse_qs(parsed_url.query)

    # å­˜å‚¨æå–çš„å‚æ•°
    params = {}

    # æ£€æŸ¥æ˜¯å¦æœ‰pathå‚æ•°éœ€è¦è§£æ
    if 'path=page/search/christmas_jump' in parsed_url.query and 'query=' in parsed_url.query:
        # æå–åµŒå¥—çš„URL
        for key, value in query_params.items():
            if key == 'query':
                nested_url = unquote(value[0])
                nested_parsed = urlparse(nested_url)
                nested_params = parse_qs(nested_parsed.query)

                # æå–åµŒå¥—URLä¸­çš„å‚æ•°
                for param in ['t', 'ch', 'u']:
                    if param in nested_params:
                        params[param] = nested_params[param][0]
                break
    else:
        # ç›´æ¥ä»æŸ¥è¯¢å‚æ•°ä¸­æå–
        for param in ['t', 'ch', 'u']:
            if param in query_params:
                params[param] = query_params[param][0]
    t = params.get('t', '')
    u = params.get('u', '')
    ch = params.get('ch', '')
    if t == '' or u == '' or ch == '':
        print(f"å‚æ•°è·å–å¼‚å¸¸: {parsed_url}")
        exit(0)
    return t, u, ch


def getReadUrl():
    url = 'https://read.tslu.cn/abaaba/getReadUrl/'
    headers = {
        'Host': 'read.tslu.cn',
        'Connection': 'keep-alive',
        'Accept': 'application/json, text/javascript, */*; q=0.01',
        'User-Agent': UA_USER_AGENT,
        'Origin': 'http://we.e9l.cn',
        'Sec-Fetch-Site': 'cross-site',
        'Sec-Fetch-Mode': 'cors',
        'Sec-Fetch-Dest': 'empty',
        'Referer': 'http://we.e9l.cn/',
        'Accept-Encoding': 'gzip, deflate, br',
        'Accept-Language': 'zh-CN,zh;q=0.9',
    }
    params = {'type': 2, 'b': str(int(time.time() * 1000)), 'token': TOKEN}

    try:
        response = requests.get(url, headers=headers, params=params, proxies=proxies).json()
        # print(f"url==={response['data']['url']}")
        return extract_parameters(response['data']['url'])
        # parsed_url = urlparse(response['data']['url'])
        # outer_params = parse_qs(parsed_url.query)
        # inner_url_encoded = outer_params.get('query', [''])[0]
        # inner_url = unquote(inner_url_encoded)
        # parsed_inner = urlparse(inner_url)
        # inner_params = parse_qs(parsed_inner.query)
        # print(inner_params)
        # t = inner_params.get('t', ['æœªè·å–t'])[0]
        # u = inner_params.get('u', ['æœªè·å–u'])[0]
        # ch = inner_params.get('ch', ['æœªè·å–ch'])[0]
        # return t, u, ch
    except Exception as e:
        print(f"å‚æ•°è·å–å¼‚å¸¸: {str(e)}")
        return 'æœªè·å–t', 'æœªè·å–u', 'æœªè·å–ch'





def check_article(aid, article_url):
    """æ–‡ç« æ£€æµ‹é€»è¾‘"""
    print(f"æ£€æµ‹æ–‡ç«  [ID:{aid}]")
    if not API_URL:
        print(f"æœªé…ç½®è‡ªåŠ¨è¿‡æ£€è¿›å…¥é€šçŸ¥æ¨é€æ‰‹åŠ¨ï¼Œè¯·åœ¨é¢æ¿é…ç½®æ–‡ä»¶è®¾ç½®å¯¹åº”æ¨é€..")
        title = "âš ï¸ QQæ£€æµ‹æ–‡ç« ï¼è¯·åœ¨120så†…å®Œæˆé˜…è¯»ï¼âš ï¸ æ¯æ¬¡é˜…è¯»ä¸å¾—å°‘äº8ç§’ï¼"
        content = f"æ–‡ç« é“¾æ¥ï¼š{article_url}  å½“å‰æ—¶é—´ {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())} å½“å‰æ—¶é—´ {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())}"
        QLAPI.notify(title, content)
        time.sleep(60)
        return True
    else:
        try:
            resp = requests.post(API_URL,
                                 json={"url": article_url, 'token': TOKEN, 'ua': UA_USER_AGENT, 'proxies': proxies},
                                 timeout=60).json()
            if resp['status'] == 'success':
                time.sleep(8)
                print("âœ… è‡ªåŠ¨è¿‡æ£€æˆåŠŸ")
                return True
            else:
                print(f"âŒ è‡ªåŠ¨è¿‡æ£€å¤±è´¥: {resp['message']}")
                return False
        except Exception as e:
            print(f"è¿‡æ£€è¯·æ±‚å¼‚å¸¸: {e}")
            return False


def sign_in():
    """æ‰§è¡Œç­¾åˆ°"""
    print("\n--- æ‰§è¡Œç­¾åˆ° ---")
    sign_url = "https://read.tslu.cn/abaaba/getxshd/"
    headers = {
        'Host': 'read.tslu.cn',
        'Connection': 'keep-alive',
        'Accept': 'application/json, text/javascript, */*; q=0.01',
        'User-Agent': UA_USER_AGENT,
        'Origin': 'http://we.e9l.cn',
        'Sec-Fetch-Site': 'cross-site',
        'Sec-Fetch-Mode': 'cors',
        'Sec-Fetch-Dest': 'empty',
        'Referer': 'http://we.e9l.cn/',
        'Accept-Encoding': 'gzip, deflate, br',
        'Accept-Language': 'zh-CN,zh;q=0.9',
    }
    params = {'token': TOKEN}

    try:
        response = requests.get(sign_url, params=params, headers=headers, proxies=proxies).json()
        if response.get("code") == 0:
            print(f"ç­¾åˆ°æˆåŠŸ! è·å¾—é‡‘å¸: {response.get('golds', 0)}")
            getHomeInfo()  # åˆ·æ–°é‡‘å¸æ˜¾ç¤º
        else:
            print(f"ç­¾åˆ°å¤±è´¥: {response.get('msg', 'æœªçŸ¥é”™è¯¯')}")
    except Exception as e:
        print(f"ç­¾åˆ°è¯·æ±‚å¼‚å¸¸: {str(e)}")
    print("--- ç­¾åˆ°ç»“æŸ ---\n")


def make_request(loop_count, initial_params, headers):
    """ä¸»å¾ªç¯è¯·æ±‚é€»è¾‘"""
    url = "https://rdapi.hzjianyue.cn/api/articleTask0428"
    current_jkey = None
    current_params = initial_params.copy()
    current_c = 1
    user_id = initial_params.get("u", "")
    channel_id = initial_params.get("ch", "")

    for i in range(loop_count):
        print(f"\n[ç¬¬{i + 1}æ¬¡å¾ªç¯] cå€¼: {current_c}")

        # å‡†å¤‡è¯·æ±‚å‚æ•°
        params = current_params.copy()
        params["c"] = current_c
        params["r"] = get_random_r()
        if i > 0 and current_jkey:
            params["jkey"] = current_jkey

        try:
            response = requests.get(url, params=params, headers=headers, proxies=proxies)
            response.raise_for_status()
            result = response.json()

            # æ£€æµ‹ç¬¬5è½®å®Œæˆ
            if result.get("code") == 1 and not result.get("data") and "ç¬¬5è½®å·²ç»å®Œæˆ" in result.get("msg", ""):
                print(f"æ£€æµ‹åˆ°ç¬¬5è½®å®Œæˆï¼Œä»»åŠ¡ç»“æŸ!")
                sign_in()
                return

            # æ£€æµ‹å…¶ä»–è½®æ¬¡å®Œæˆ
            if result.get("code") == 1 and not result.get("data") and "è½®å·²ç»å®Œæˆ" in result.get("msg", ""):
                print(f"è½®æ¬¡å®Œæˆ: {result.get('msg')}ï¼Œç»ˆæ­¢å¾ªç¯")
                getHomeInfo()
                return

            # æ£€æµ‹å…¶ä»–è½®æ¬¡å®Œæˆ
            if result.get("code") == 1 and not result.get("data") and "æš‚æ—¶æ²¡æœ‰æ–‡ç« å¯ä¾›é˜…è¯»" in result.get("msg", ""):
                print(f"è½®æ¬¡å®Œæˆ: {result.get('msg')}ï¼Œç»ˆæ­¢å¾ªç¯")
                getHomeInfo()
                return

            # æ£€æµ‹å…¶ä»–è½®æ¬¡å®Œæˆ
            if result.get("code") == 1 and not result.get("data") and "æ‚¨é˜…è¯»æ•°é‡å·²è¾¾ä»Šæ—¥ä¸Šé™" in result.get("msg", ""):
                print(f"è½®æ¬¡å®Œæˆ: {result.get('msg')}ï¼Œç»ˆæ­¢å¾ªç¯")
                getHomeInfo()
                return

            # æ£€æµ‹å…¶ä»–è½®æ¬¡å®Œæˆ
            if result.get("code") == 1 and not result.get("data") and "å‰è¢«å¾®ä¿¡åˆ¤æ–­ä¸ºæ— æ•ˆç”¨æˆ·" in result.get("msg", ""):
                print(f"è½®æ¬¡å®Œæˆ: {result.get('msg')}ï¼Œç»ˆæ­¢å¾ªç¯")
                getHomeInfo()
                return

            # æ£€æµ‹é“¾æ¥å¤±æ•ˆ
            if result.get("code") == 1 and result.get("msg") == "å½“å‰é“¾æ¥å·²å¤±æ•ˆ, è¯·è·å–æœ€æ–°é“¾æ¥å“¦" and not result.get(
                    "data"):
                print("é“¾æ¥å¤±æ•ˆï¼Œé‡æ–°è·å–å‚æ•°...")
                new_t, new_u, new_ch = getReadUrl()
                current_params.update({"t": new_t, "u": new_u, "ch": new_ch})
                user_id, channel_id = new_u, new_ch
                current_jkey = None
                current_c = 1
                continue

            # å¤„ç†æ­£å¸¸å“åº”
            if result.get("code") == 0:
                data = result.get("data", {})
                current_jkey = data.get("jkey")
                aid = data.get("aid", 0)
                article_url = data.get("url", "")

                _biz = extract_biz(article_url)
                print(f"ğŸ“– å¼€å§‹é˜…è¯»: {article_url}", flush=True)
                print(f"æ–‡ç« ä¿¡æ¯ - : {_biz} | å·²è¯»/æ€»æ•°: {data.get('readNum', 0)}/{data.get('totalNum', 0)}")
                if _biz in ['MzkyNzYxMDA0Mw==', 'MzkzNzk3Mjk2MQ==', 'MzkyMjYxMDAwMA==', 'Mzk3NTc4MzI1NQ==',
                            'MzI5MjYyNDIxOA==', 'Mzk0OTYxMDEwNQ==', 'MzkzNjk3MjIxNg==', 'MzkzMTk0ODYxOQ==',
                            'MzkzODk3Mjk2NQ==', 'MzIwOTc0MzYxMg==', 'MzkyOTk0NzcyNw==', 'MzkxOTg4MjUzOA==',
                            'Mzk4ODQ2OTYyMg==',
                            'MzkzMjk3MDgxNQ==', 'MzkzOTYxMDQ2Mw==', 'MzkzODk0NzkwMg==', 'MzkwODYwOTUxOQ=='] or len(
                    current_jkey) > 35:
                    if not check_article(_biz, article_url):
                        return

                current_c += 1
            else:
                print(f"è¯·æ±‚å¼‚å¸¸: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                current_c += 1

        except requests.exceptions.RequestException as e:
            print(f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {e}")
            current_c += 1
        except json.JSONDecodeError:
            print("å“åº”æ ¼å¼é”™è¯¯")
            current_c += 1

        # å»¶è¿Ÿå¤„ç†
        if i < loop_count - 1:
            delay = random.randint(8, 20)
            print(f"ç­‰å¾…{delay}ç§’...")
            time.sleep(delay)

    print(f"\næ‰€æœ‰{loop_count}æ¬¡å¾ªç¯å®Œæˆ")
    getHomeInfo()


if __name__ == "__main__":
    QQ_TOKEN = os.getenv('QQ_TOKEN')
    if not QQ_TOKEN:
        print("è¯·å…ˆé…ç½®è´¦å·ä¿¡æ¯(QQ_TOKEN)")
        exit()

    if UA_USER_AGENT:
        print(f"âœ… å·²é…ç½®ua: {UA_USER_AGENT}")
    else:
        print("â„¹ï¸ æœªé…ç½®uaï¼Œåœæ­¢è¿è¡Œ")
        exit()

    if PROXY_URL:
        print(f"âœ… å·²é…ç½®ä»£ç†: {PROXY_URL}")
    else:
        print("â„¹ï¸ æœªé…ç½®ä»£ç†ï¼Œé‡‡ç”¨æœ¬åœ°è¯·æ±‚")

    TOKENS = QQ_TOKEN.split('#')
    print(f"å…±{len(TOKENS)}ä¸ªè´¦å·")
    for TOKEN in TOKENS:
        proxies = {}
        if PROXY_URL:
            try:
                get_ip = requests.get(PROXY_URL).text.strip()
                print('è·å–ä»£ç†ï¼š{0}'.format(get_ip))
                proxies = {
                    "http": f"http://{get_ip}",
                    "https": f"http://{get_ip}",
                }
            except Exception as e:
                print('è·å–ä»£ç†å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°ç½‘ç»œæ‰§è¡Œ')
        getHomeInfo()  # åˆå§‹é¦–é¡µä¿¡æ¯
        t, u, ch = getReadUrl()

        initial_params = {
            "t": t,
            "u": u,
            "ch": ch,
            "pageshow": "",
        }

        headers = {
            "Host": "rdapi.hzjianyue.cn",
            "Connection": "keep-alive",
            "User-Agent": UA_USER_AGENT,
            "X-Requested-With": "XMLHttpRequest",
            "Accept": "*/*",
            "Sec-Fetch-Site": "cross-site",
            "Sec-Fetch-Mode": "cors",
            "Sec-Fetch-Dest": "empty",
            "Accept-Encoding": "gzip, deflate, br",
            "Accept-Language": "zh-CN,zh;q=0.9"
        }

        loop_times = 39
        print(f"\nå¼€å§‹æ‰§è¡Œ{loop_times}æ¬¡å¾ªç¯...")
        print(initial_params)
        make_request(loop_times, initial_params, headers)
